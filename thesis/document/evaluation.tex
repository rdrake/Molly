\chapter{Experimental Evaluation}
\label{chap:experimental-evaluation}
	In this chapter we evaluate our implementation of the system for transforming data in the relational model to the document model and vice versa described in \cref{chap:tale-of-two-data-models}.  We detail the implementation details in \cref{sec:implementation}, the methodology and evaluation in \cref{sec:runtime-evaluation}, and provide a number of lessons we learned from evaluating our system in \cref{sec:lessons-learned}.
	
	\section{Implementation}
	\label{sec:implementation}
		The system was implemented in Clojure, which \textcquote{clj-home}{is a dynamic programming language that targets the \gls{jvm}}.  Clojure was chosen due to its rich, immutable, and persistent data structures, excellent concurrency support, and seamless \gls{jvm} interoperability.  These features were discussed in detail in \cref{sec:features-of-clojure}.
		
		\subsection{Code Base Statistics}
			The system consists of over 800 lines of Clojure, along with approximately 550 lines of Python.  The Python code is used to construct the data set by crawling the course information site, as well as to aggregate the benchmark data produced by the system, producing graphs.
			
			All development has occurred on GitHub \cite{molly-repo}. \todo{Expand on this.  Why is GitHub significant?}
	
	\section{The Data Corpus}
	\label{sec:data-corpus}
		The data corpus was derived from the \gls{uoit} mycampus database.  An \gls{html} crawler was written in Python that scraped the information from the \gls{uoit} class schedule search page.  This data was parsed, normalized, then placed in a SQLite database.
		
		The data corpus consists of numerous classes of objects.  These are campuses (\cref{tbl:corpus-campus}), courses (\cref{tbl:corpus-course}), instructors (\cref{tbl:corpus-instructor}), locations (\cref{tbl:corpus-location}), schedules (\cref{tbl:corpus-schedule}), sections (\cref{tbl:corpus-section}), subjects (\cref{tbl:corpus-subject}), and terms (\cref{tbl:corpus-term}).  A graph representation of how these classes of objects are related can be found in \cref{fig:schema-graph}.  The data corpus is defined in \cref{chap:data-corpus-def}
		
		The number of objects, as of the publication of this thesis, can be found in \cref{tbl:data-corpus-count}.
		
		\begin{table}[H]
			\centering
			\begin{tabular}{lr}
			\toprule
			Class & Count \\
			\midrule
			Campus & 8 \\
			Course & 1797 \\
			Instructor & 560 \\
			Location & 220 \\
			Schedule & 20985 \\
			Section & 6211 \\
			Subject & 68 \\
			Term & 32 \\
			\bottomrule
			\end{tabular}
			
			\caption{Number of objects in data corpus, grouped by class}
			\label{tbl:data-corpus-count}
		\end{table}
	
	\section{Runtime Evaluation}
	\label{sec:runtime-evaluation}
		Scripts were written to coordinate the execution, collection, and transformation of the performance data of our implementation.
		
		\subsection{Methodology}
			We used Criterium\footnote{\url{http://hugoduncan.org/criterium/}} to handle the execution of the benchmarks as it handles unique concerns stemming from benchmarking on the \gls{jvm}.  These issues, identified by \citeauthor{rob-java-bench-08} \cite{rob-java-bench-08}, include:
			
			\begin{itemize}
				\item Statistical processing of multiple evaluations
				\item Inclusion of a warm-up period, designed to allow the JIT compiler to optimize its code
				\item Purging of the garbage collector before testing, to isolate timings from GC state prior to testing
				\item A final forced garbage collection after testing to estimate impact of cleanup on the timing results
			\end{itemize}
		
			This requires a much longer runtime as each function must be invoked numerous times.
			
			During evaluation, Criterium collects performance metrics.  Upon completion of the evaluation, it performs statistical analysis of these metrics using the bootstrap procedure developed by \citeauthor{efron-87} \cite{efron-87}.  These metrics include mean, samples, variance, quartiles, outliers, and more.
		
			\subsubsection{Data Collection}
			\label{sec:data-collection}
				The performance metrics computed by Criterium are returned as a Clojure map data structure.  The evaluation process may take several hours to complete, necessitating a separation between data collection and post-processing.  These metrics are stored offline for further processing.
				
				In order to utilize the Clojure output in Python, a data interchange format (\gls{json}) is used.  The benchmark function writes the Criterium performance analysis out as a \gls{json} string to stdout and the output is captured by the benchmark script.  An example of this \gls{json} output is given in \cref{fig:criterium-json-output}.
				
				\begin{figure}[H]
					\centering % Pointless, but who knows in the future.
					\begin{verbatim}
                    [{
                        "max-hops": ...,
                        "method": ...,
                        "results": {
                            "execution-count": ...,
                            "final-gc-time": ...,
                            "lower-q": [...],
                            "mean": [...],
                        ...
                    }, ...]
					\end{verbatim}
					
					\caption{Partial \gls{json} output from Criterium.}
					\label{fig:criterium-json-output}
				\end{figure}
		
		\subsection{Performance}
		\label{sec:performance}
			Performance was measured for the various system components.  An analysis of the metrics collected is presented in this section.
			
			\subsubsection{Indexing}
				The indexing process is computationally intensive but short lived.  After the initial \gls{jvm} warmup period, the time required to construct the index scales with the number of named tuples and relations between them.
				
				\begin{table}[H]
					\centering
					\begin{tabular}{ll}
						\toprule
						Number of Groups & Elapsed Time (s) \\
						\midrule
						1 & 16.895 \\
						2 & 21.624 \\
						3 & 24.436 \\
						4 & 24.528 \\
						5 & 25.334 \\
						\bottomrule
					\end{tabular}
					
					\caption{Indexing time growth by number of entity groups}
					\label{tbl:index-growth-entity-groups}
				\end{table}
				
				We see in \cref{tbl:index-growth-entity-groups} the indexing time increases considerably between 1 and 2 groups.  The number of entity groups also grew considerably, explaining the time increase.  The number of entity groups grew at a slower pace from 2 to 3, and 3 to 5, causing the reduced increase in elapsed time.
				
			\subsubsection{Keyword Search}
			
			
			\subsubsection{Graph Search}
				The worst-case performance of \gls{bfs} is \(\mathcal{O}(n^2)\).  This is reflected in \cref{fig:method-runtime-tkes-25} which follows an exponential growth curve.  In an attempt to mitigate the rapid increase in search time, concurrent variants of \gls{bfs} were also implemented and benchmarked.
				
				We see in \cref{fig:method-runtime-tkes-25} the decrease in rate of growth is not as high as expected.  \gls{bfs} is the slowest, closely followed by \gls{bfs} with references and \gls{bfs} with atoms.
				
				\begin{figure}[H]
					\centering
					\input{figures/charts/lineplot-tkv-50-tkes-25-tke-5-stopsat4.pgf}
					
					\caption{Comparison of time taken per hop between all methods (top-\(k\) entities:  25), target found}
					\label{fig:method-runtime-tkes-25-stopsat4}
				\end{figure}
				
				The most likely cause for the similarity is how the concurrency is implemented.  In our implementation, we concurrently search for neighbours.  These neighbours must be added to the frontier before proceeding.  Therefore the algorithm must synchronize upon completion of the neighbour search in order to populate the new frontier.
				
				Atoms are less expensive to use than references as they are handled in an uncoordinated manner in Clojure, reducing the amount of overhead \cite{narkis-12}.  This explains the difference between the two concurrent implementations of \gls{bfs}.
				
				%\begin{table}[H]
				%	\centering
				%	\begin{tabular}{lll}
				%		\toprule
				%		Hops & Elapsed Time (s) & Factor \\
				%		\midrule
				%		1 & 0.00092 & N/A \\
				%		2 & 0.00342 & 3.72x \\
				%		3 & 0.02015 & 5.89x \\
				%		4 & 0.05267 & 2.61x \\
				%		\bottomrule
				%	\end{tabular}
				%	
				%	\caption{}
				%\end{table}
				
				Also of note is the growth of \cref{fig:method-runtime-tkes-25-stopsat4} compared to that of \cref{fig:method-runtime-tkes-25}.  In the former figure, the target is located by the fourth hop.  In the latter, the target is not found.  This leads to hops 4 through 8 having approximately the same runtime as one another.
				
				\begin{figure}[H]
					\centering
					\input{figures/charts/lineplot-tkv-50-tkes-25-tke-5.pgf}
					
					\caption{Comparison of time taken per hop between all methods (top-\(k\) entities:  25), target not found}
					\label{fig:method-runtime-tkes-25}
				\end{figure}
	
	\section{Lessons learned}
	\label{sec:lessons-learned}
		The system evaluation has yielded several important insights.  We have found that the simplest algorithms are the easiest to parallelize.  The reduced complexity, and thus state, reduces the amount of shared data that must be synchronized.  This allows for higher concurrency.
		
		Clojure's \gls{stm} implementation is simple to use and effective.  A few simple functions provide a powerful concurrency model.
		
		Sometimes a simpler approach to concurrency is the most appropriate one.  In our evaluation, atoms provided better performance than references.  Atoms allow for finer granularity in concurrency, reducing the overhead associated with references.  This is desirable in situations that do not require much shared state.
		
		Clojure is a powerful language that encouraged us to write correct code first, then optimize it later.  
		\begin{itemize}
			\item Simple algorithms are easier to parallelize
			\item STM is effective: transactions do not rollback (that much), so we observe impressive speed-up in concurrent versions.
			\item Fine tuning is beneficial: atom is better than ref.
			\item The clojure way: correctness first, runtime optimization latter (ref to atom is natural).
		\end{itemize}