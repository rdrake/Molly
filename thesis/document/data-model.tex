% !TEX root = Thesis.tex
The term ``data model'' refers to a notation for describing data and/or information.  It consists of the data structure, operations that may be performed on the data, as well as constraints placed on the data \cite{dbsys-06}.

In this chapter we provide a formal definition of the relational data model, discuss its merits, its shortcomings, and contrast it to the document data model.  Contrary to the relational model, the document model permits fast and flexible keyword search without requiring explicit domain knowledge of the data.  In addition, we demonstrate the feasibility of encoding a relational model into a document model in a lossless manner.

\section{Relational Model}
	In its most basic form, the relational data model is built upon sets and tuples.  Each of these sets consist of a set of finite possible values.  Tuples are constructed from these sets to form relations.
	
	\begin{defn}[Named Tuple]
	\label{def:named-tuple}
		A named tuple $t$ is an instance of a relation $r$, consisting of values corresponding to the attributes of $r$.  For example,
		
		$$t = \left\{\mathrm{name}: \textrm{``Jack Bauer''}, \mathrm{age}: 39\right\}$$
		
		We denote the attributes of $t$ as $\fcn{ATTR}{t} = \left\{\mathrm{name}, \mathrm{age}\right\}$  The values are $t\lbrack \mathrm{name}\rbrack = \textrm{``Jack Bauer''}$, and $t\lbrack \mathrm{age}\rbrack = 39$.
	\end{defn}
	
	\begin{defn}[Relation]
	\label{def:relation}
		A relation $r$ is a set of named tuples, $r = \left\{t_1, t_2, \dotsc, t_n\right\}$, such that all the named tuples share the same attributes.
		
		$$\forall t, t' \in r, \fcn{ATTR}{t} = \fcn{ATTR}{t'}$$
		
		For example,
		
		$$r = \left\{
			\begin{array}{l}
				\left\{\mathrm{name}: \textrm{``Jack Bauer''}, \mathrm{age}: 39\right\}, \\
				\left\{\mathrm{name}: \textrm{``Bruce Wayne''}, \mathrm{age}: 39\right\}, \\
				\left\{\mathrm{name}: \textrm{``Clark Kent''}, \mathrm{age}: 45\right\}
			\end{array}
		\right\}$$
		
		Relations are typically represented as tables.
		
		\begin{table}[!ht]
			\centering
			\begin{tabular}{ll}
				\toprule
				name & age \\
				\midrule
				``Jack Bauer'' & 39 \\
				``Bruce Wayne'' & 39 \\
				``Clark Kent'' & 45 \\
				\bottomrule
			\end{tabular}
			
			\caption{Person table}
			\label{tbl:person}
		\end{table}
	\end{defn}
	
	\begin{defn}[Keys]
	\label{def:keys}
		Keys are constraints imposed on relations.  A key constraint $K$ on a relation $r$ is a subset of $\fcn{ATTR}{r}$ which may uniquely identify a tuple.  Formally, we say $r$ satisfies the key constraint $K$, denoted as $r \models K$, subject to
		
		$$\forall t, t' \in r, t \not= t' \implies t[K] \not= t'[K]$$
		
		For example, in Table~\ref{tbl:person}, the relation satisfies the key constraint $\left\{\mathrm{name}\right\}$, but not $\left\{\mathrm{age}\right\}$.
	\end{defn}
	
	\begin{defn}[Foreign Keys]
	\label{def:foreign-keys}
		A foreign key constraint applies to two relations, $r_1, r_2$.  It asserts that values of certain attributes of $r_1$ must appear as values of some corresponding attributes of $r_2$.  A foreign key constraint is written as
		
		$$\theta = r_1(a_1, a_2, \dotsc, a_k) \rightarrow r_2(b_1, b_2, \dotsc, b_k)$$
		
		where $a_i \subseteq \fcn{ATTR}{r_1}$ and $b_i \subseteq \fcn{ATTR}{r_2}$.  We say $(r_1, r_2)$ satisfies $\theta$, denoted as $(r_1, r_2) \models \theta$, if
		
		$$\forall t \in r_1, \exists t' \in r_2 \mid t\lbrack a_1, a_2, \dotsc, a_k\rbrack = t'\lbrack b_1, b_2, \dotsc, b_k]$$
		
		\begin{ex}
			Suppose we have a relation Superhero(name, superpower).  We can impose a FK constraint of
			
			$$\textrm{Superhero(name)} \rightarrow \textrm{Person(name)}$$
		\end{ex}
	\end{defn}
	
	\begin{defn}[Relational Database]
	\label{def:relational-database}
		A relational database, $d$, is a named collection of relations (as defined by Definition~\ref{def:relation}, keys (as defined by Definition~\ref{def:keys}), and foreign key constraints (as defined by Definition~\ref{def:foreign-keys}.
		
		We use $\fcn{Name}{d}$ to denote the name of $d$, $\fcn{Rel}{d}$ the list of relations in $d$, $\fcn{Key}{d}$ the list of key constraints of $d$, and $\fcn{FK}{d}$ the list of foreign key constraints of $d$.
	\end{defn}
	
	\subsection{Schema Group}
		\begin{defn}[Schema Graph]
			If we view relations as vertices, and foreign key constraints as edges, a database $d$ can be viewed as a \emph{schema graph} $G$, formally defined as
			
			\begin{eqnarray*}
				\mathrm{vertices}:  V(G) &=& \fcn{REL}{d} \\
				\mathrm{edges}:  E(G) &=& \fcn{FK}{d}
			\end{eqnarray*}
		\end{defn}
		
		\begin{ex}
			Given the following schema
			
			\begin{figure}[!ht]
				\centering
				
				Superhero(name, power) \\
				Person(name, age, birthplace) \\
				Planet(name, size, age, destroyed, galaxy) \\
				Link(name, peer, relation type) \\
			\end{figure}
			
			and the following foreign key constraints
			
			\begin{eqnarray*}
				\textrm{Superhero(name)} &\rightarrow& \textrm{Person(name)} \\
				\textrm{Person(birthplace)} &\rightarrow& \textrm{Planet(name)} \\
				\textrm{Link(name)} &\rightarrow& \textrm{Person(name)} \\
				\textrm{Link(peer)} &\rightarrow& \textrm{Person(name)}
			\end{eqnarray*}
			
			we produce the following schema graph.
			
			\todo{ER diagram or something of schema.}
			
			The relational data model is particularly powerful for analytic queries.  Given the schema below above, one can formulate the following analytic queries in a query language known as SQL.
			
			List all superheroes whose home planet has not been destroyed.
			
			SELECT Person.name FROM Person JOIN Planet on Person.birthplace = Planet.name WHERE NOT Planet.destroyed;
		\end{ex}
		
	\subsection{Entity Group}
		\begin{defn}[Entity Group]
			An entity group is a forest, T,  of tuples interconnected by join conditions defined by the foreign key constraints in the schema graph.  Given two vertices $t_1, t_2'\in V\left(T\right)$, it must be that:

			$\exists r_1, r_2\in \fcn{REL}{d}$ such that $t_1 \in r_1$, $t_2\in r_2$, and $\left(r_1, r_2\right)\in G$.  This is to say that $t_1$ and $t_2$ belong to two relations that are connected by the schema graph.

			Let $r_1\left(a_1, \dotsc, a_k\right) \to r_2\left(b_1, \dotsc, b_k\right)$ be the FK that connects $r_1, r_2$.  We further assert that $t_1\lbrack a_1, \dotsc, a_k\rbrack = t_2\lbrack b_1, \dotsc, b_k\rbrack$.
		\end{defn}
		
		The motivation of entity groups is to define complex structured objects that can include more information than individual tuples in the relations.
		
		Example:
		
		name: Clark Kent
		age: ?
		birthplace: Krypton
		superpower: ?
		friends: ?.
		enemies: ?
		
		This object (the profile of Clark Kent) can only be represented as an entity group as no single tuple in any of the relations has such detailed information.  This is a result of normalization of the schema.

	\subsection{Pros and Cons of the Relational Model}
		In order to better understand the motivation behind this work, it is important to examine the strong as well as weak points of the relational model.
		
		For each item of pro and con, use the running example to illustrate them.
		
		For example:
		
		1. both queries are executable by Postgres
		2. if we try to insert ``Clark Kent'' again, it will be rejected.  If we insert ``Frog Boy'' as a superhero, it will be rejected.  If we change the age of ``Clark Kent'' this will only need to occur in a single place.
		3. Change the ``Ken'' and ``CSCI'' to some superhero example.
		
		Do the same for CONS.
		
		E.g. Tell me something about ``Batman''.  We need to know the relation and attributes involved in order to author the SQL query.  ``Supermen'' will return nothing.
		
		\subsection{Pros}
			\begin{itemize}
				\item Well supported by relational algebra and relational databases (RDBMS)
				\item Clean and consistent database instances (A\underline{C}ID?)
				\item Can use queries to resolve instance-level connectivity
					\begin{itemize}
						\item How is "Ken" connected to "CSCI 3030U"?
					\end{itemize}
					\todo{More examples of queries}
			\end{itemize}
		
		\subsection{Cons}
			\begin{itemize}
				\item Must know the relational schema
					\begin{enumerate}
						\item Know table/attribute names
						\item Know join paths (schema)
					\end{enumerate}
				\item Inflexible string matching options  (basically just have \texttt{LIKE}), substring matching
				\item Must know SQL
				\item All queries must be re-written upon schema changes (rename, change in join path, etc.)
				\item Not adaptive to new join path (e.g.\ newly created entity group, deleted E.G.\, etc.)
			\end{itemize}
	
		\begin{itemize}
			\item Good for analytics (aggregation, selection) if user has domain knowledge of the schema.
			\item Bad for exploratory queries.
			\item Bad if user doesn't know SQL
			\item Bad for flexibility
		\end{itemize}

\section{Document Model}
	In this section we formally define the document model.
	
	Documents are a unit of information.  The definition of unit can vary.  It may represent an email, a book chapter, a memo, etc.  Contained within each document is a set of terms.
	
	In contrast to the relational model, the document model represents semi-structured data.  Examples of information suitable to the document model includes emails, memos, book chapters, etc.
	
	\begin{defn}[Document]
	\label{def:document}
		A document is a unit of information.  The definition of unit can vary; it may represent an email, a book chapter, a memo, etc.  The $k$-th document is denoted by $d_k$, which uniquely identifies the document within the document space.
		
		Documents may be comprised of one or more fields, $\fcn{Fields}{d}$.  They can be thought of as a dictionary.
		
		$$
			d_k = \left\{
				\begin{array}{c}
					f_1 \rightarrow v_1 \\
					f_2 \rightarrow v_2 \\
					\vdots \\
					f_n \rightarrow v_n
				\end{array}
			\right\}
		$$
		
		 %as well as one or more terms (Definition~\ref{def:term}), denoted $\fcn{Term}{d} = \lbrack t_1, t_2, \dotsc, t_n\rbrack$.
	\end{defn}
	
	\begin{defn}[Field]
	\label{def:field}
		A field, $f$, is a dictionary item within a document $d$.
		
		$$f \in \fcn{Fields}{d}$$
		
		
	\end{defn}
	
	\begin{defn}[Document Collection]
	\label{def:document-collection}
		Given a set of documents $D = \left\{d_1, d_2, \dotsc, d_n\right\}$, we say that $d_1, d_2, \dotsc, d_n$ are the documents within the collection $D$.  The size of $D$ is denoted by $N$.
	\end{defn}
	
	\begin{defn}[Term]
	\label{def:term}
	
	\end{defn}
	
	\begin{ex}
		Let $\{d_1, d_2, d_3\}$ be the set of documents, each representing a course title.
		
		\begin{eqnarray*}
			d_1 &=& \textrm{Software Design and Analysis} \\
			d_2 &=& \textrm{Software Quality Assurance} \\
			d_3 &=& \textrm{Analysis and Design of Algorithms}
		\end{eqnarray*}
		
		The simplest method would be to perform a linear scan through every document, returning each document that contains a search query.
		
		If we were to issue a query $q = \textrm{``Design''}$, we would receive a result of $\{d_1, d_3\}$.  Unfortunately this search must be performed every time a user issues a search query.  Thus the search time would grow linearly with the number of documents, as well as the length of each document.
		
		Another method would be to construct an incidence matrix of each term in each document, then consult this matrix when a search query is issued.  Using this method would incur an initial penalty, but this would only occur once.
		
		$$
			\begin{array}{lccc}
				& d_1 & d_2 & d_3 \\
				\textrm{Algorithms} & 0 & 0 & 1 \\
				\textrm{Analysis} & 1 & 0 & 1 \\
				\textrm{Assurance} & 0 & 1 & 0 \\
				\textrm{Design} & 1 & 0 & 1 \\
				\textrm{Quality} & 0 & 1 & 0 \\
				\textrm{Software} & 1 & 1 & 0
			\end{array}
		$$
		
		A search then becomes a simple lookup in the matrix.  A search for ``Algorithms'' would yield the binary string \texttt{001}.  It also allows for simple boolean operations.  A query of ``Analysis'' \textsc{AND} ``Software'' would become
		
		$$101~\textsc{AND}~110$$
		
		which would yield 100, or the set $\{d_1\}$.
		
		While an incidence matrix solves the problem of having to scan every document for every search, it introduces additional problems.  There may be a large number of documents, each with its own unique terms.  This causes the matrix to become very sparse.
		
		In order to deal with the problem of a sparse matrix, we use an inverted list index.  It consists of a sorted dictionary of terms, each pointing to one or more documents that contain that term.
		
		\begin{figure}[!ht]
			\centering
			
			\subcaptionbox{Initial inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{ll}
					\toprule
					Term & Doc ID \\
					\midrule
					software & 1 \\
					design & 1 \\
					analysis & 1 \\
					software & 2 \\
					quality & 2 \\
					assurance & 2 \\
					analysis & 3 \\
					design & 3 \\
					algorithm & 3 \\
					\bottomrule
				\end{tabular}
			}
			\subcaptionbox{Sorted inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{ll}
					\toprule
					Term & Doc ID \\
					\midrule
					algorithm & 3 \\
					analysis & 1 \\
					analysis & 3 \\
					assurance & 2 \\
					design & 1 \\
					design & 3 \\
					quality & 2 \\
					software & 1 \\
					software & 2 \\
					\bottomrule
				\end{tabular}
			}
			\subcaptionbox{Completed inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{lrl}
					\toprule
					Term & $\df$ & Doc ID \\
					\midrule
					algorithm & 1 & $\lbrack 3\rbrack$ \\
					analysis & 2 & $\lbrack 1, 3\rbrack$ \\
					assurance & 1 & $\lbrack 2\rbrack$ \\
					design & 2 & $\lbrack 1, 3\rbrack$ \\
					quality & 1 & $\lbrack 2\rbrack$ \\
					software & 2 & $\lbrack 1, 2\rbrack$ \\
					\bottomrule
				\end{tabular}
			}
			
			\caption{Construction of the inverted list index}
		\end{figure}
		
		This permits more space efficient storage.
		
		Note:  The terms in the inverted list index are sorted.  This permits binary search, resulting in lookup performance of $\mathcal{O}\left(\log{n}\right)$.
	\end{ex}
	
	\subsection{Keyword Query Vectorization}
		We now have a method for determining which documents contain a particular term.  While this allows a user to manually sort through all of the results, it does not provide an indication of the importance, or score, of each result.
		
		\subsubsection{Term Frequency}
			In order to measure importance of a term within a document, we look at the number of occurrences of said term within the document versus how many individual terms are in the document.  This is the term frequency.
			
			$$\tf_{t, d} = 0.5 + \frac{0.5 \times \mathrm{f}_{t, d}}{\max{\{\mathrm{f}_{w, d} \mid w \in d}\}}$$
			
			\todo{Add consistency for this equation.  Maybe find another variant not from Wikipedia.}
			
		\subsection{Inverse Document Frequency}
			The inverse document frequency is a measurement of the rarity of a term in the space of all documents.  A term that occurs multiple times within a single document is considered less rare if said term also occurs within many documents.
			
			$$\idf_t = \log{\frac{N}{\df_t}}$$
		
		These two functions are combined to measure the importance of a term within a document.
		
		$$\tfidf_{t, d} = \tf_{t, d} \times \idf_t$$
		
		\subsubsection{Scoring a Document}
			With the ability to score a document for a particular term, we can now think of a document $d$ score for a query $q$, where $q = \lbrack t_1, t_2, \dotsc, t_n\rbrack$, as a vector.
			
			$$
				\mathrm{score}_{q, d} = 
				\left[
				\begin{array}{c}
					\tfidf_{t_1, d} \\
					\tfidf_{t_2, d} \\
					\vdots \\
					\tfidf_{t_n, d}
				\end{array}
				\right]
			$$
			
			Therefore the overall score is as follows.
			
			$$\score_{q, d} = \sum_{t \in q} \tfidf_{t, d}$$
		
	\subsection{Cosine Similarity}
		$$\similarity_{d_1, d_2} = \cos{\theta} = \frac{d_1 \cdot d_2}{\lVert d_1\rVert\lVert d_2\rVert}$$
	
	\subsection{Jaccard Similarity}
		$$\similarity_{d_1, d_2} = \frac{\mid d_1 \cap d_2\mid}{\mid d_1 \cup d_2\mid}$$
	
	\subsection{Extending the Document Model}
		In reality not all documents contain completely unstructured information.  For example, an email contains additional information beyond the message such as subject, recipient, etc.  This additional information is stored in fields.
		
		\begin{ex}
			Every course has two main attributes, a code and a title.  These attributes could be stored in a single document.  However, we may wish to apply different analysis techniques to each attribute type.
			
			\begin{table}
				\centering
				\begin{tabular}{ll}
					\toprule
					Field & Contents \\
					\midrule
					code & CSCI 3030U \\
					title & Database Systems and Concepts \\
					\bottomrule
				\end{tabular}
			\end{table}
			
			In the case of a code, we likely want it copied verbatim.  An example tokenization of ``CSCI 3030U'' would be $\left\{\texttt{csci}, \texttt{3030u}\right\}$.  A standard analyzer would have eliminated the second token.
			
			Whereas a standard analyzer would work well for course titles.  For example, an ideal tokenization of ``Database Systems and Concepts'' would be $\left\{\texttt{database}, \texttt{system}, \texttt{concept}\right\}$.
			
			Plural forms of words were reduced to their singular form, and the stop word ``and'' was eliminated.
		\end{ex}
	
	\begin{itemize}
		\item Definition of keyword search queries: vectorization of documents (tf-idf) and queries.  Models of distance between documents and queries (cosine-distance, jaccard distance, BM25).
		\item Expressing documents in the universal design pattern (aka list+dict)
		\item Document graph
	\end{itemize}

\section{Pro and con of document model (1 day)}
	\begin{itemize}
		\item Good: exploratory queries using keywords (google)
		\item Good: easy (or no) syntax
		\item Good: fuzzy matching (using n-gram)
		\item Bad: No analytics
	\end{itemize}
		
		\section{Best of both worlds (4 days, week 3)}
	\begin{itemize}
		\item Hybrid database defined by both the relational model and the document model
		\item Translation between relational objects (entities and entity) groups to documents.
		\item Translation of documents back to relational objects.
		\item Proof of lossless translation between relational space and document space
	\end{itemize}