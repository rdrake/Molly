% !TEX root = Thesis.tex
In this chapter we provide a formal definition of the relational data model, discuss its merits, its shortcomings, and contrast it to the document data model.  Contrary to the relational model, the document model permits fast and flexible keyword search without requiring explicit domain knowledge of the data.  In addition, we demonstrate the feasibility of encoding a relational model into a document model in a lossless manner.

The term ``data model'' refers to a notation for describing data and/or information.  It consists of the data structure, operations that may be performed on the data, as well as constraints placed on the data \cite{dbsys-06}.

\section{Relational model with star schema}
%	In order to understand the shortcomings of the relational model, we must first 
	In this section we formally define the relational model.
	
	\subsection{Relational Model of Data}
		In its most basic form, the relational data model is built upon sets and tuples.  Each of these sets consist of a set of finite possible values.  Tuples are constructed from these sets to form relations.
		
		Formally, a Relation is defined as follows \cite{codd-90}:
		
		\begin{defn}{Relation}
			Given a list of sets $\lbrack S_1, S_2, \ldots, S_n\rbrack$, let $R$ be a relation on these $n$ sets if it is a set of $n$-tuples, with the first component from $S_1$, the second component from $S_2$, and so on.
			
			More concisely,
			
			$$R \subset S_1 \times S_2 \times \ldots \times S_n$$
			
			$R$ is said to be of degree $n$, denoted as $\mathrm{deg}_R$.  Each of the sets on which one or more relation is based is called the domain, denoted as $\mathrm{dom}_S$.
		\end{defn}
		
		\begin{ex}
			Consider the following sets
			\begin{eqnarray*}
				S_1 &=& \left\{\textrm{``Winter 2014''}, \textrm{``Fall 2013''}\right\} \\
				S_2 &=& \left\{\textrm{``CSCI 3030U''}, \textrm{``CSCI 4020U''}\right\} \\
				S_3 &=& \left\{\textrm{``Ken Pu''}\right\}
			\end{eqnarray*}
			which have the properties
			\begin{eqnarray*}
				\mathrm{dom}_{S_1} &=& \mathrm{terms} \\
				\mathrm{dom}_{S_2} &=& \mathrm{courses} \\
				\mathrm{dom}_{S_3} &=& \mathrm{instructors}
			\end{eqnarray*}
			By taking the Cartesian product, we arrive at the following set of tuples
			$$
				S_1 \times S_2 \times S_3 =
				\left\{
					\begin{array}{l}
						\left(\textrm{``Winter 2014''}, \textrm{``CSCI 3030U''}, \textrm{``Ken Pu''}\right) \\
						\left(\textrm{``Fall 2013''}, \textrm{``CSCI 3030U''}, \textrm{``Ken Pu''}\right) \\
						\left(\textrm{``Winter 2014''}, \textrm{``CSCI 4020U''}, \textrm{``Ken Pu''}\right) \\
						\left(\textrm{``Fall 2013''}, \textrm{``CSCI 4020U''}, \textrm{``Ken Pu''}\right)
					\end{array}
				\right\}
			$$
			Furthermore, given the relation
			$$
				R =
				\left\{
					\begin{array}{l}
						\left(\textrm{``Winter 2014''}, \textrm{``CSCI 4020U''}, \textrm{``Ken Pu''}\right) \\
						\left(\textrm{``Fall 2013''}, \textrm{``CSCI 3030U''}, \textrm{``Ken Pu''}\right)
					\end{array}
				\right\}
			$$
			We see that $R \subset S_1 \times S_2 \times S_3$, with $\mathrm{deg}_R = 3$.
		\end{ex}
		
		
		
		%The relational model, as suggested by its name, is based on the concept of relations.  These relations are 2-dimensional tables, where the rows are n-tuples and the columns are attributes.  Any number of these attributes may also be keys.  In addition to attributes and keys, a relation has a name.
		
		%Given a relation $r$, we denote the name of $r$ as $\textsc{Name}\lbrack r\rbrack$.  
		
		\begin{defn}
		\label{def:database}
			Let $d$ be a database instance.  A database is comprised of three main components:
			
			\begin{itemize}
				\item $\textsc{Name}\lbrack d\rbrack \rightarrow$ string
				\item $\textsc{Rel}\lbrack d\rbrack \rightarrow$ list(REL)
				\item $\textsc{FK}\lbrack d\rbrack \rightarrow$ list(FK)
			\end{itemize}
		\end{defn}
		
		\begin{defn}{Relation}
		\label{def:relation}
		
			Let $r \in \textsc{Rel}\lbrack d\rbrack$, where $d$ is defined in Definition \ref{def:database}.  A relation is comprised of three main components:
			
			\begin{itemize}
				\item $\textsc{Name}\lbrack r\rbrack$ : string
				\item $\textsc{Attr}\lbrack r\rbrack$ : list(ATTR)
				\item $\textsc{Key}\lbrack r\rbrack$ : list(ATTR)
			\end{itemize}
			
			The first is a \texttt{string} representation of the relation.  The second is a list of attributes that make up entries, or tuples, in the relation.  The third is a list of the relation's attributes that uniquely identify the tuple within the relation.  That is, $\textsc{Key}\lbrack r\rbrack \subseteq \textsc{Attr}\lbrack r\rbrack$.
		\end{defn}
		
		\begin{defn}{Attribute}
		
			Let $a \in \textsc{Attr}\lbrack r\rbrack$, where $r$ is defined in Definition \ref{def:relation}.  An attribute is comprised of two main components:
			
			\begin{itemize}
				\item $\textsc{Name}\lbrack a\rbrack$
				\item $\textsc{Type}\lbrack a\rbrack$
			\end{itemize}
		
			Note:  Lower case letters (e.g.\ $a, b, c, \ldots$) are attributes.
		\end{defn}
		
		\begin{defn}{Foreign Key}
		
			Let $\theta \in \textsc{FK}\lbrack d\rbrack$ be a FK instance,where $d$ is defined in Definition \ref{def:database}.  A foreign key is comprised of two main components:
			
			\begin{itemize}
				\item $\textsc{From}\lbrack fk\rbrack = (\textsc{Rel}_{s}\lbrack\theta\rbrack, \textsc{Attr}_{s}\lbrack\theta\rbrack)$
				\item $\textsc{To}\lbrack fk\rbrack = (\textsc{Rel}_{t}\lbrack\theta\rbrack, \textsc{Attr}_{t}\lbrack\theta\rbrack)$
			\end{itemize}
			
			Note:  $\theta, \phi$ are the FK constraints
		\end{defn}
	
	\subsection{Star Join Schema to Form Entity Groups}
		A network (forest) of tuples, jointed via some existing $\theta \in \textsc{FK}\lbrack d\rbrack$.
		
		The schema of entity group $G$ is defined as vertices of $G$:
		
		$$V(G) \subseteq \textsc{Rel}(DB)$$
		
		Relation $r$ in the space of vertices of $G$, $V(G)$, may be a table or a computed view.
		
		$$r \in V(G)$$
		
		It is also defined as the edges of $G$, or $E(G)$, in the form of
		
		$$r(a_1, a_2, \ldots, a_k) \rightarrow s(b_1, b_2, \ldots, b_k)$$
		
		where $a_i \in \textsc{attr}\lbrack r\rbrack$, $b_i \in \textsc{attr}\lbrack s\rbrack$, with the additional constraint of $r, s \in V(G)$.
		
		\begin{ex}
			\begin{eqnarray*}
				Instructor(name) &\rightarrow& Schedule(instructor) \\
				Schedule(code) &\rightarrow& Course(id)
			\end{eqnarray*}
		\end{ex}
	
	\subsection{Instances of an Entity Group}
		\xymatrix{
			& r_1 \ar[dl]^{\theta_{1, 2}} \ar[dr]^{\theta_{1, 3}} & \\
			r_2 & & r_3 \ar[d]^{\theta_{2, 3}} \\
			& & r_4
		}
		
		Instances are obtained by the following process.
		
		For $r_i(a_{i, 1}, a{i, 2}, \ldots, a_{i, k}) \rightarrow r_j(b_{j, 1}, b_{j, 2}, \ldots, b{j, k})$
		
		$$c_{ii, j} = \bigwedge^k_{n=1} (a_{i, n} = b_{j, n})$$
		
		\begin{eqnarray*}
			\textsc{View}\lbrack G\rbrack &=& \bowtie_{\theta_{ij}} (r_i, r_j) \\
			&=& r_1 \bowtie_{\theta_{1, 2}} r_2 \bowtie_{\theta_{2, 3}} r_3 \ldots \bowtie_{\theta_{n, n+1}} r_n
		\end{eqnarray*}
		
		where $r_1, r_2, r_3, \ldots, r_n$ are relations discovered by a depth-first search traversal of $G$.
		
		Each tuple in $\textsc{View}\lbrack G\rbrack$ is an instance of entity group $G$.
		
		Motivation:
		
		\todo{Diagram of schema-level graph (FKs, relations)}
		
		Database schema
		
		Vertices:  $\textsc{Rel}\lbrack d\rbrack$
		
		Edges:  $\textsc{FK}\lbrack d\rbrack$
		
		The entity graphs are overlapping subgraphs at the schema level.
		
		Question:
		
		How to determine connectivity at the instance level?
	
	\begin{itemize}
		\item ER style relational schema
		\item Star join schema to form entity groups
		\item Expressing relational objects using universal design pattern (describing data using scalar, lists and dictionaries).
		\item Relational object graph
	\end{itemize}

\section{Pros and Cons of the Relational Model}
	In order to better understand the motivation behind this work, it is important to examine the strong as well as weak points of the relational model.
	
	\subsection{Pros}
		\begin{itemize}
			\item Well supported by relational algebra and relational databases (RDBMS)
			\item Clean and consistent database instances (A\underline{C}ID?)
			\item Can use queries to resolve instance-level connectivity
				\begin{itemize}
					\item How is "Ken" connected to "CSCI 3030U"?
				\end{itemize}
				\todo{More examples of queries}
		\end{itemize}
	
	\subsection{Cons}
		\begin{itemize}
			\item Must know the relational schema
				\begin{enumerate}
					\item Know table/attribute names
					\item Know join paths (schema)
				\end{enumerate}
			\item Inflexible string matching options  (basically just have \texttt{LIKE}), substring matching
			\item Must know SQL
			\item All queries must be re-written upon schema changes (rename, change in join path, etc.)
			\item Not adaptive to new join path (e.g.\ newly created entity group, deleted E.G.\, etc.)
		\end{itemize}

	\begin{itemize}
		\item Good for analytics (aggregation, selection) if user has domain knowledge of the schema.
		\item Bad for exploratory queries.
		\item Bad if user doesn't know SQL
		\item Bad for flexibility
	\end{itemize}

\section{Document model (4 days, week 2)}
	In this section we formally define the document model.
	
	Documents are a unit of information.  The definition of unit can vary.  It may represent an email, a book chapter, a memo, etc.  Contained within each document is a set of terms.
	
	In contrast to the relational model, the document model represents unstructured data.  Examples of information suitable to the document model includes emails, memos, book chapters, etc.
	
	\begin{ex}
		Let $\{d_1, d_2, d_3\}$ be the set of documents, each representing a course title.
		
		\begin{eqnarray*}
			d_1 &=& \textrm{Software Design and Analysis} \\
			d_2 &=& \textrm{Software Quality Assurance} \\
			d_3 &=& \textrm{Analysis and Design of Algorithms}
		\end{eqnarray*}
		
		The simplest method would be to perform a linear scan through every document, returning each document that contains a search query.
		
		If we were to issue a query $q = \textrm{``Design''}$, we would receive a result of $\{d_1, d_3\}$.  Unfortunately this search must be performed every time a user issues a search query.  Thus the search time would grow linearly with the number of documents, as well as the length of each document.
		
		Another method would be to construct an incidence matrix of each term in each document, then consult this matrix when a search query is issued.  Using this method would incur an initial penalty, but this would only occur once.
		
		$$
			\begin{array}{lccc}
				& d_1 & d_2 & d_3 \\
				\textrm{Algorithms} & 0 & 0 & 1 \\
				\textrm{Analysis} & 1 & 0 & 1 \\
				\textrm{Assurance} & 0 & 1 & 0 \\
				\textrm{Design} & 1 & 0 & 1 \\
				\textrm{Quality} & 0 & 1 & 0 \\
				\textrm{Software} & 1 & 1 & 0
			\end{array}
		$$
		
		A search then becomes a simple lookup in the matrix.  A search for ``Algorithms'' would yield the binary string \texttt{001}.  It also allows for simple boolean operations.  A query of ``Analysis'' \textsc{AND} ``Software'' would become
		
		$$101 \textsc{AND} 110$$
		
		which would yield 100, or the set $\{d_1\}$.
		
		While an incidence matrix solves the problem of having to scan every document for every search, it introduces additional problems.  There may be a large number of documents, each with its own unique terms.  This causes the matrix to become very sparse.
		
		In order to deal with the problem of a sparse matrix, we use an inverted list index.  It consists of a sorted dictionary of terms, each pointing to one or more documents that contain that term.
		
		\begin{figure}[!ht]
			\centering
			
			\subcaptionbox{Initial inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{ll}
					\toprule
					Term & Doc ID \\
					\midrule
					software & 1 \\
					design & 1 \\
					analysis & 1 \\
					software & 2 \\
					quality & 2 \\
					assurance & 2 \\
					analysis & 3 \\
					design & 3 \\
					algorithm & 3 \\
					\bottomrule
				\end{tabular}
			}
			\subcaptionbox{Sorted inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{ll}
					\toprule
					Term & Doc ID \\
					\midrule
					algorithm & 3 \\
					analysis & 1 \\
					analysis & 3 \\
					assurance & 2 \\
					design & 1 \\
					design & 3 \\
					quality & 2 \\
					software & 1 \\
					software & 2 \\
					\bottomrule
				\end{tabular}
			}
			\subcaptionbox{Completed inverted list index}[0.33\textwidth]{
				\centering
				\begin{tabular}{lrl}
					\toprule
					Term & $\df$ & Doc ID \\
					\midrule
					algorithm & 1 & $\lbrack 3\rbrack$ \\
					analysis & 2 & $\lbrack 1, 3\rbrack$ \\
					assurance & 1 & $\lbrack 2\rbrack$ \\
					design & 2 & $\lbrack 1, 3\rbrack$ \\
					quality & 1 & $\lbrack 2\rbrack$ \\
					software & 2 & $\lbrack 1, 2\rbrack$ \\
					\bottomrule
				\end{tabular}
			}
			
			\caption{Construction of the inverted list index}
		\end{figure}
		
		This permits more space efficient storage.
		
		Note:  The terms in the inverted list index are sorted.  This permits binary search, resulting in lookup performance of $\mathcal{O}\left(\log{n}\right)$.
	\end{ex}
	
	\subsection{Keyword Query Vectorization}
		We now have a method for determining which documents contain a particular term.  While this allows a user to manually sort through all of the results, it does not provide an indication of the importance, or score, of each result.
		
		\subsubsection{Term Frequency}
			In order to measure importance of a term within a document, we look at the number of occurrences of said term within the document versus how many individual terms are in the document.  This is the term frequency.
			
			$$\tf_{t, d} = 0.5 + \frac{0.5 \times \mathrm{f}_{t, d}}{\max{\{\mathrm{f}_{w, d} \mid w \in d}\}}$$
			
		\subsection{Inverse Document Frequency}
			The inverse document frequency is a measurement of the rarity of a term in the space of all documents.  A term that occurs multiple times within a single document is considered less rare if said term also occurs within many documents.
			
			$$\idf_t = \log{\frac{N}{\df_t}}$$
		
		These two functions are combined to measure the importance of a term within a document.
		
		$$\tfidf_{t, d} = \tf_{t, d} \times \idf_t$$
		
		\subsubsection{Scoring a Document}
			With the ability to score a document for a particular term, we can now think of a document $d$ score for a query $q$, where $q = \lbrack t_1, t_2, \ldots, t_n\rbrack$, as a vector.
			
			$$
				\mathrm{score}_{q, d} = 
				\left[
				\begin{array}{c}
					\tfidf_{t_1, d} \\
					\tfidf_{t_2, d} \\
					\vdots \\
					\tfidf_{t_n, d}
				\end{array}
				\right]
			$$
			
			Therefore the overall score is as follows.
			
			$$\score_{q, d} = \sum_{t \in q} \tfidf_{t, d}$$
		
	\subsection{Cosine Similarity}
		$$\similarity_{d_1, d_2} = \cos{\theta} = \frac{d_1 \cdot d_2}{\lVert d_1\rVert\lVert d_2\rVert}$$
	
	\subsection{Jaccard Similarity}
		$$\similarity_{d_1, d_2} = \frac{\mid d_1 \cap d_2\mid}{\mid d_1 \cup d_2\mid}$$
	
	\subsection{Extending the Document Model}
		In reality not all documents contain completely unstructured information.  For example, an email contains additional information beyond the message such as subject, recipient, etc.  This additional information is stored in fields.
		
		\begin{ex}
			Every course has two main attributes, a code and a title.  These attributes could be stored in a single document.  However, we may wish to apply different analysis techniques to each attribute type.
			
			\begin{table}
				\centering
				\begin{tabular}{ll}
					\toprule
					Field & Contents \\
					\midrule
					code & CSCI 3030U \\
					title & Database Systems and Concepts \\
					\bottomrule
				\end{tabular}
			\end{table}
			
			In the case of a code, we likely want it copied verbatim.  An example tokenization of ``CSCI 3030U'' would be $\left\{\texttt{csci}, \texttt{3030u}\right\}$.  A standard analyzer would have eliminated the second token.
			
			Whereas a standard analyzer would work well for course titles.  For example, an ideal tokenization of ``Database Systems and Concepts'' would be $\left\{\texttt{database}, \texttt{system}, \texttt{concept}\right\}$.
			
			Plural forms of words were reduced to their singular form, and the stop word ``and'' was eliminated.
		\end{ex}
	
	\begin{itemize}
		\item Definition of keyword search queries: vectorization of documents (tf-idf) and queries.  Models of distance between documents and queries (cosine-distance, jaccard distance, BM25).
		\item Expressing documents in the universal design pattern (aka list+dict)
		\item Document graph
	\end{itemize}

\section{Pro and con of document model (1 day)}
	\begin{itemize}
		\item Good: exploratory queries using keywords (google)
		\item Good: easy (or no) syntax
		\item Good: fuzzy matching (using n-gram)
		\item Bad: No analytics
	\end{itemize}
		
		\section{Best of both worlds (4 days, week 3)}
	\begin{itemize}
		\item Hybrid database defined by both the relational model and the document model
		\item Translation between relational objects (entities and entity) groups to documents.
		\item Translation of documents back to relational objects.
		\item Proof of lossless translation between relational space and document space
	\end{itemize}